def google_rss_search(query: str):
    # ØªØ±Ù…ÙŠØ² Ø§Ù„Ø¨Ø­Ø« Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ğŸ› ï¸
    encoded_query = urllib.parse.quote(f"{query} Ø¹Ø±ÙˆØ¶ Ø§Ù„Ø£Ø±Ø¯Ù†")
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl=ar&gl=JO&ceid=JO:ar"
    
    feed = feedparser.parse(url)
    deals = []

    for entry in feed.entries:
        full_text = entry.title + " " + entry.get("summary", "")
        
        # 1. ØªØ·ÙˆÙŠØ± Ø§Ù„ØµÙ†Ø§Ø±Ø©: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Ù¡Ù¥Ù ) ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© (150) ğŸ£
        # Ø£Ø¶ÙÙ†Ø§ \u0660-\u0669 Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡Ù†Ø¯ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        price_match = re.search(r"([\d\u0660-\u0669]+(\.[\d\u0660-\u0669]+)?)\s?(Ø¯ÙŠÙ†Ø§Ø±|JD|JOD|Ø¯\.Ø£)", full_text)
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…ÙƒØªØ´Ù Ø¥Ù„Ù‰ Ø±Ù‚Ù… Ø­Ù‚ÙŠÙ‚ÙŠ (Float) Ù„Ù„ØªØ±ØªÙŠØ¨ ğŸ’¸
        price = None
        if price_match:
            price_str = price_match.group(1)
            # ÙƒÙˆØ¯ Ø¨Ø³ÙŠØ· Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¥Ù„Ù‰ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª
            arabic_digits = "Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©"
            english_digits = "0123456789"
            translation_table = str.maketrans(arabic_digits, english_digits)
            price = float(price_str.translate(translation_table))

        # 2. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: Ø­Ø°Ù Ø§Ø³Ù… Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ù…Ù† Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ğŸ›ï¸
        clean_title = entry.title.split(" - ")[0]

        deals.append({
            "Ø§Ù„Ù…Ù†ØªØ¬ ğŸ›’": clean_title,
            "Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ ğŸ’¸": price if price else "ÙŠØ­Ø¯Ø¯ Ù„Ø§Ø­Ù‚Ø§Ù‹",
            "Ø§Ù„Ù…ØµØ¯Ø± ğŸ›ï¸": entry.source.title if hasattr(entry, 'source') else "Ø¬ÙˆØ¬Ù„",
            "Ø§Ù„Ø±Ø§Ø¨Ø· ğŸ”—": entry.link
        })
    
    # 3. ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: Ø§Ù„Ø£Ø±Ø®Øµ Ø£ÙˆÙ„Ø§Ù‹ (Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯ Ø§Ù„Ø³Ø¹Ø±) ğŸ“‰
    return sorted(deals, key=lambda x: (x["Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ ğŸ’¸"] is None, x["Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ ğŸ’¸"]))
